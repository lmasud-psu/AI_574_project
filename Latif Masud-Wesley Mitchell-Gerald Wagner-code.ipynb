{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Online banking fraud detection using natural language processing techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Team 9:**\n",
    "\n",
    "- Latif Masud\n",
    "- ​Wesley Mitchell\n",
    "- Gerald Wagner​\n",
    "\n",
    "**Course:** AI 574 – Natural Language Processing (Spring 2025)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Statement\n",
    "* This project  .....\n",
    "    \n",
    "    \n",
    "    \n",
    "* **Keywords:** House price prediction, real estate ,..., "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Collection\n",
    "* Source(url):\n",
    "* Short Description : The data set of Boston Housing from Harrison and Rubinfeld (1978)\n",
    "\n",
    "* Keywords: House price, room, zip code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required packages\n",
    "\n",
    "* Add instructions to install the required packages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# online banking transaction data\n",
    "path = Path('./data/Fraud Detection with Natural Language Processing.pkl')\n",
    "df = pd.read_pickle(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocabulary of API calls\n",
    "path_vocab = Path('./data/vocab.csv')\n",
    "df_vocab = pd.read_csv(path_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary mapping ids in transaction data to vocabulary\n",
    "vocab = df_vocab['Name'].to_list()\n",
    "id_to_action = {i:a for i, a in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "\n",
    "* Enumerate and present the main steps you preformed in the data preprocessing\n",
    "* Add your code and interpret the outcome of main steps/functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the tokenized user actions during online banking to API endpoint calls\n",
    "actions_raw = df['actions'].to_list()\n",
    "\n",
    "actions = []\n",
    "for action in actions_raw:\n",
    "\n",
    "    action_str = (action.replace('[', '')\n",
    "           .replace(']', '')\n",
    "           .replace(' ', '')\n",
    "           .split(','))\n",
    "    \n",
    "    action_ids = []\n",
    "    for id in action_str:\n",
    "        if id:\n",
    "            \n",
    "            action_ids.append(id_to_action[int(id)])\n",
    "\n",
    "    actions.append(action_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methodology\n",
    "\n",
    "1. Explan your Deep Learning process / methodology\n",
    "\n",
    "\n",
    "\n",
    "2. Introduce the Deep Neural Networks you used in your project\n",
    " * Model 1\n",
    "    * Description \n",
    " \n",
    " * Model 2\n",
    "    * Description\n",
    " \n",
    " * Ensemble method\n",
    "     * Description \n",
    " \n",
    " \n",
    "3. Add keywords  \n",
    "**Keywords:** natural language processing, sentiment analysis, clustering, binary classification, multi-label classification, prediction\n",
    "\t___\n",
    " **Example**\n",
    "* ConvNet\n",
    "    * A convolutional neural network (CNN, or ConvNet) is a class of deep neural networks, most commonly applied to analyzing visual imagery(source Wikipedia). \n",
    " \n",
    "* **Keywords:** supervised learning, classification, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Fitting and Validation\n",
    "\n",
    "1. model 1 \n",
    "    - decription \n",
    "2. model 2\n",
    "    - decription "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation \n",
    "\n",
    "* Examine your models (coefficients, parameters, errors, etc...)\n",
    "\n",
    "* Compute and interpret your results in terms of accuracy, precision, recall, ROC etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issues / Improvements\n",
    "1. Dataset is very small\n",
    "2. Use regularization / initialization\n",
    "3. Use cross-validaiton\n",
    "4. ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  References\n",
    "   - Academic (if any)\n",
    "   - Online (if any)\n",
    "\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Credits\n",
    "\n",
    "- If you use and/or adapt your code from existing projects, you must provide links and acknowldge the authors. Keep in mind that all documents in your projects and code will be check against the official plagiarism detection tool used by Penn State ([Turnitin](https://turnitin.psu.edu))\n",
    "\n",
    "> *This code is based on .... (if any)*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
